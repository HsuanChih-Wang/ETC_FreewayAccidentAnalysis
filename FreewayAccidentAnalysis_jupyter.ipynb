{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data------------------------------------------\n",
    "data = pd.read_csv(\"output/fw1_2020_north_final(afterSQL).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>startkilo</th>\n",
       "      <th>endkilo</th>\n",
       "      <th>year</th>\n",
       "      <th>startTime_millionSec</th>\n",
       "      <th>endTime_millionSec</th>\n",
       "      <th>crash</th>\n",
       "      <th>lane</th>\n",
       "      <th>minlane</th>\n",
       "      <th>addlane</th>\n",
       "      <th>...</th>\n",
       "      <th>heavy_rate</th>\n",
       "      <th>Var_volume</th>\n",
       "      <th>Var_PCU</th>\n",
       "      <th>Var_Speed_volume</th>\n",
       "      <th>Var_Speed_PCU</th>\n",
       "      <th>fw1_northcol</th>\n",
       "      <th>index</th>\n",
       "      <th>DayType</th>\n",
       "      <th>PeakHour</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5042301.0</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5042301.0</td>\n",
       "      <td>5042301.0</td>\n",
       "      <td>5042301.0</td>\n",
       "      <td>5042301.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5.042301e+06</td>\n",
       "      <td>5.042301e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.582616e+05</td>\n",
       "      <td>4.999714e+01</td>\n",
       "      <td>5.201380e+01</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.593618e+09</td>\n",
       "      <td>1.593618e+09</td>\n",
       "      <td>9.176366e-04</td>\n",
       "      <td>2.979111e+00</td>\n",
       "      <td>1.249929e-01</td>\n",
       "      <td>1.249929e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.631513e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.582616e+05</td>\n",
       "      <td>3.880700e-01</td>\n",
       "      <td>1.558146e-01</td>\n",
       "      <td>1.145993e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.879540e+05</td>\n",
       "      <td>2.857905e+01</td>\n",
       "      <td>2.860726e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.129113e+06</td>\n",
       "      <td>9.129113e+06</td>\n",
       "      <td>3.074660e-02</td>\n",
       "      <td>6.611323e-01</td>\n",
       "      <td>3.307109e-01</td>\n",
       "      <td>3.307109e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282397e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.879540e+05</td>\n",
       "      <td>6.117106e-01</td>\n",
       "      <td>3.626795e-01</td>\n",
       "      <td>6.900811e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.577808e+09</td>\n",
       "      <td>1.577808e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.050470e+05</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.600000e+01</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.585712e+09</td>\n",
       "      <td>1.585712e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.700000e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050470e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2.245720e+05</td>\n",
       "      <td>4.800000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.593618e+09</td>\n",
       "      <td>1.593618e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.260000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.245720e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.727150e+05</td>\n",
       "      <td>7.400000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.601524e+09</td>\n",
       "      <td>1.601524e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.970000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.727150e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>8.423000e+05</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>1.008000e+02</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.609430e+09</td>\n",
       "      <td>1.609430e+09</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.423000e+05</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                num     startkilo       endkilo       year  \\\n",
       "count  5.042301e+06  5.042301e+06  5.042301e+06  5042301.0   \n",
       "mean   2.582616e+05  4.999714e+01  5.201380e+01     2020.0   \n",
       "std    1.879540e+05  2.857905e+01  2.860726e+01        0.0   \n",
       "min    0.000000e+00  0.000000e+00  2.000000e+00     2020.0   \n",
       "25%    1.050470e+05  2.400000e+01  2.600000e+01     2020.0   \n",
       "50%    2.245720e+05  4.800000e+01  5.000000e+01     2020.0   \n",
       "75%    3.727150e+05  7.400000e+01  7.600000e+01     2020.0   \n",
       "max    8.423000e+05  9.800000e+01  1.008000e+02     2020.0   \n",
       "\n",
       "       startTime_millionSec  endTime_millionSec         crash          lane  \\\n",
       "count          5.042301e+06        5.042301e+06  5.042301e+06  5.042301e+06   \n",
       "mean           1.593618e+09        1.593618e+09  9.176366e-04  2.979111e+00   \n",
       "std            9.129113e+06        9.129113e+06  3.074660e-02  6.611323e-01   \n",
       "min            1.577808e+09        1.577808e+09  0.000000e+00  2.000000e+00   \n",
       "25%            1.585712e+09        1.585712e+09  0.000000e+00  3.000000e+00   \n",
       "50%            1.593618e+09        1.593618e+09  0.000000e+00  3.000000e+00   \n",
       "75%            1.601524e+09        1.601524e+09  0.000000e+00  3.000000e+00   \n",
       "max            1.609430e+09        1.609430e+09  3.000000e+00  5.000000e+00   \n",
       "\n",
       "            minlane       addlane  ...    heavy_rate  Var_volume    Var_PCU  \\\n",
       "count  5.042301e+06  5.042301e+06  ...  5.042301e+06   5042301.0  5042301.0   \n",
       "mean   1.249929e-01  1.249929e-01  ...  1.631513e-01         0.0        0.0   \n",
       "std    3.307109e-01  3.307109e-01  ...  1.282397e-01         0.0        0.0   \n",
       "min    0.000000e+00  0.000000e+00  ...  0.000000e+00         0.0        0.0   \n",
       "25%    0.000000e+00  0.000000e+00  ...  7.700000e-02         0.0        0.0   \n",
       "50%    0.000000e+00  0.000000e+00  ...  1.260000e-01         0.0        0.0   \n",
       "75%    0.000000e+00  0.000000e+00  ...  1.970000e-01         0.0        0.0   \n",
       "max    1.000000e+00  1.000000e+00  ...  1.000000e+00         0.0        0.0   \n",
       "\n",
       "       Var_Speed_volume  Var_Speed_PCU  fw1_northcol         index  \\\n",
       "count         5042301.0      5042301.0           0.0  5.042301e+06   \n",
       "mean                0.0            0.0           NaN  2.582616e+05   \n",
       "std                 0.0            0.0           NaN  1.879540e+05   \n",
       "min                 0.0            0.0           NaN  0.000000e+00   \n",
       "25%                 0.0            0.0           NaN  1.050470e+05   \n",
       "50%                 0.0            0.0           NaN  2.245720e+05   \n",
       "75%                 0.0            0.0           NaN  3.727150e+05   \n",
       "max                 0.0            0.0           NaN  8.423000e+05   \n",
       "\n",
       "            DayType      PeakHour          Hour  \n",
       "count  5.042301e+06  5.042301e+06  5.042301e+06  \n",
       "mean   3.880700e-01  1.558146e-01  1.145993e+01  \n",
       "std    6.117106e-01  3.626795e-01  6.900811e+00  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  5.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00  1.100000e+01  \n",
       "75%    1.000000e+00  0.000000e+00  1.700000e+01  \n",
       "max    2.000000e+00  1.000000e+00  2.300000e+01  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['crash', 'lane', 'minlane', 'addlane', 'totalwidth', 'lanewidth',\n",
      "       'inshoulder', 'outshoulder', 'upslope', 'downslope', 'upslopelength',\n",
      "       'downslopelength', 'maxupslope', 'maxdownslope', 'curvelength',\n",
      "       'minradius', 'continuouscurve', 'interchange', 'tunnellength',\n",
      "       'tunnelin', 'tunnelout', 'shouderoallow', 'camera', 'service',\n",
      "       'windspeed', 'rain', 'volume_S', 'volume_L', 'volume_T', 'volume',\n",
      "       'PCU', 'Speed_volume', 'Speed_PCU', 'heavy_rate', 'CrashType',\n",
      "       'DayType', 'PeakHour', 'Hour'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#drop data\n",
    "data.drop(['num', 'startkilo', 'endkilo', 'year', 'date', \n",
    "           'starttime', 'startTime_millionSec', 'endtime', 'endTime_millionSec'], \n",
    "          axis=1, inplace=True)\n",
    "# Since the values of feature \"speed limit\" are all the same, we drop the feature\n",
    "data.drop(['speedlimit'], axis=1, inplace=True)\n",
    "data.drop(['pavement', 'cement', 'remark', 'one'], axis=1, inplace=True)\n",
    "# unrelated factors\n",
    "data.drop(['fw1_northcol', 'index'], axis=1, inplace=True)\n",
    "# drop columns \n",
    "data.drop(['minradiuslength',\n",
    "           'Var_windspeed', 'Var_rain', 'Var_volume', \n",
    "           'Var_PCU', 'Var_Speed_volume', 'Var_Speed_PCU'], axis=1, inplace=True)\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num                  int64\n",
      "crash                int64\n",
      "lane                 int64\n",
      "minlane              int64\n",
      "addlane              int64\n",
      "totalwidth         float64\n",
      "lanewidth          float64\n",
      "inshoulder           int64\n",
      "outshoulder          int64\n",
      "upslope            float64\n",
      "downslope          float64\n",
      "upslopelength        int64\n",
      "downslopelength      int64\n",
      "maxupslope         float64\n",
      "maxdownslope       float64\n",
      "curvelength          int64\n",
      "minradius            int64\n",
      "continuouscurve      int64\n",
      "interchange          int64\n",
      "tunnellength         int64\n",
      "tunnelin             int64\n",
      "tunnelout            int64\n",
      "shouderoallow        int64\n",
      "camera               int64\n",
      "service              int64\n",
      "windspeed          float64\n",
      "rain               float64\n",
      "volume_S             int64\n",
      "volume_L             int64\n",
      "volume_T             int64\n",
      "volume               int64\n",
      "PCU                float64\n",
      "Speed_volume         int64\n",
      "Speed_PCU            int64\n",
      "heavy_rate         float64\n",
      "CrashType           object\n",
      "DayType              int64\n",
      "PeakHour             int64\n",
      "Hour                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data['rain'] has many non-numeric values: \"&\", try to fix them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num                  int64\n",
      "crash                int64\n",
      "lane                 int64\n",
      "minlane              int64\n",
      "addlane              int64\n",
      "totalwidth         float64\n",
      "lanewidth          float64\n",
      "inshoulder           int64\n",
      "outshoulder          int64\n",
      "upslope            float64\n",
      "downslope          float64\n",
      "upslopelength        int64\n",
      "downslopelength      int64\n",
      "maxupslope         float64\n",
      "maxdownslope       float64\n",
      "curvelength          int64\n",
      "minradius            int64\n",
      "continuouscurve      int64\n",
      "interchange          int64\n",
      "tunnellength         int64\n",
      "tunnelin             int64\n",
      "tunnelout            int64\n",
      "shouderoallow        int64\n",
      "camera               int64\n",
      "service              int64\n",
      "windspeed          float64\n",
      "rain               float64\n",
      "volume_S             int64\n",
      "volume_L             int64\n",
      "volume_T             int64\n",
      "volume               int64\n",
      "PCU                float64\n",
      "Speed_volume         int64\n",
      "Speed_PCU            int64\n",
      "heavy_rate         float64\n",
      "CrashType           object\n",
      "DayType              int64\n",
      "PeakHour             int64\n",
      "Hour                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# data['rain'] has many non-numeric values: \"&\", try to fix them -> 20220707 has fixed this. \n",
    "# data['rain'] = pd.to_numeric(data['rain'], errors='coerce').fillna(0, downcast='float')\n",
    "# data['windspeed'] = pd.to_numeric(data['windspeed'], errors='coerce').fillna(0, downcast='float')\n",
    "# data['Speed_volume'] = pd.to_numeric(data['Speed_volume'], errors='coerce').fillna(0, downcast='float')\n",
    "# data['Speed_PCU'] = pd.to_numeric(data['Speed_PCU'], errors='coerce').fillna(0, downcast='float')\n",
    "# data['heavy_rate'] = pd.to_numeric(data['heavy_rate'], errors='coerce').fillna(0, downcast='float')\n",
    "\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrashType\n",
      "A1          7\n",
      "A2        278\n",
      "A3       4273\n",
      "\\N    5037743\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby(\"CrashType\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to categorial type.................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to categorial type..................\n",
    "data[\"crash\"] = data[\"crash\"].astype(\"category\") \n",
    "## !!!!! WARNING!!! ordered = True means the variable is ordered, which means it can be compared. \n",
    "## Otherwise, it can not be compared. \n",
    "data[\"minlane\"] = data[\"minlane\"].astype(\"category\")\n",
    "data[\"addlane\"] = data[\"addlane\"].astype(\"category\")\n",
    "data[\"continuouscurve\"] = data[\"continuouscurve\"].astype(\"category\")\n",
    "data[\"interchange\"] = data[\"interchange\"].astype(\"category\")\n",
    "data[\"tunnelin\"] = data[\"tunnelin\"].astype(\"category\")\n",
    "data[\"tunnelout\"] = data[\"tunnelout\"].astype(\"category\")\n",
    "data[\"shouderoallow\"] = data[\"shouderoallow\"].astype(\"category\")\n",
    "data[\"camera\"] = data[\"camera\"].astype(\"category\")\n",
    "data[\"service\"] = data[\"service\"].astype(\"category\")\n",
    "data[\"DayType\"] = data[\"DayType\"].astype(\"category\")\n",
    "data[\"PeakHour\"] = data[\"PeakHour\"].astype(\"category\")\n",
    "data[\"Hour\"] = data[\"Hour\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation heatmap 變數相關性確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "roadGeometryRelatedData = pd.concat([data['lane'], data['totalwidth'], data['lanewidth'],\n",
    "                                     data['inshoulder'], data['outshoulder'], data['upslopelength'],\n",
    "                                     data['downslopelength'], data['maxupslope'], data['maxdownslope'], \n",
    "                                     data['curvelength'], data['minradius'], data['tunnellength']], axis=1)\n",
    "trafficFlowRelatedData = pd.concat([data['PCU'], data['volume'], data['volume_S'], data['volume_T'], data['volume_L'], data['heavy_rate']], axis=1) \n",
    "weatherRelatedData = pd.concat([data['windspeed'], data['rain']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# draw a heatmap -> roadGeometryRelatedData\n",
    "corr = roadGeometryRelatedData.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "plt.figure(figsize=(len(roadGeometryRelatedData.columns), len(roadGeometryRelatedData.columns)))\n",
    "hm = sns.heatmap(round(corr,2),annot=True, ax=ax, cmap='coolwarm', linewidths=.5)\n",
    "f.subplots_adjust(top=0.8)\n",
    "ax.set_ylim(12, 0)\n",
    "t= f.suptitle('Data Features Correlation Heatmap', fontsize=12)\n",
    "plt.show() #畫出熱力圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a heatmap -> trafficRelatedData\n",
    "corr = trafficFlowRelatedData.corr()\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "plt.figure(figsize=(len(trafficFlowRelatedData.columns), len(trafficFlowRelatedData.columns)))\n",
    "hm = sns.heatmap(round(corr,2),annot=True, ax=ax, cmap='coolwarm', linewidths=.5)\n",
    "f.subplots_adjust(top=0.8)\n",
    "ax.set_ylim(8, 0)\n",
    "t= f.suptitle('Data Features Correlation Heatmap', fontsize=12)\n",
    "plt.show() #畫出熱力圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a heatmap -> trafficRelatedData\n",
    "corr = weatherRelatedData.corr()\n",
    "f, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "plt.figure(figsize=(len(weatherRelatedData.columns), len(weatherRelatedData.columns)))\n",
    "hm = sns.heatmap(round(corr,2),annot=True, ax=ax, cmap='coolwarm', linewidths=.5)\n",
    "f.subplots_adjust(top=0.8)\n",
    "ax.set_ylim(2, 0)\n",
    "t= f.suptitle('Data Features Correlation Heatmap', fontsize=12)\n",
    "plt.show() #畫出熱力圖"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by correlation analysis results, we delete data['Speed_volume'], data['volume_S'], data['volume_L'] and data['volume_T'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(['Speed_volume', 'volume_S', 'volume_T', 'volume_L'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before AI prediciton model: Seperare X and Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features that are used in the model into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lane', 'minlane', 'addlane', 'totalwidth', 'lanewidth', 'inshoulder', 'outshoulder', 'upslope', 'downslope', 'upslopelength', 'downslopelength', 'maxupslope', 'maxdownslope', 'curvelength', 'minradius', 'continuouscurve', 'interchange', 'tunnellength', 'tunnelin', 'tunnelout', 'shouderoallow', 'camera', 'service', 'windspeed', 'rain', 'volume_S', 'volume_L', 'volume_T', 'volume', 'PCU', 'heavy_rate', 'DayType', 'PeakHour', 'Hour']\n"
     ]
    }
   ],
   "source": [
    "#Select features that are used in the model into a list\n",
    "features = list(data.columns)\n",
    "for feature in ['crash', 'CrashType', 'Speed_volume', 'Speed_PCU']:\n",
    "    features.remove(feature)  #Remove features\n",
    "    \n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (OPTION) Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(n=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crash\n",
      "0    999086\n",
      "1       904\n",
      "2        10\n",
      "3         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_sample.groupby(\"crash\").size()) #Check crash number in the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Data: DownSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         crash  lane minlane addlane  totalwidth  lanewidth  inshoulder  \\\n",
      "262035       0     2       0       0         8.0        7.5           0   \n",
      "4143296      0     3       0       0        15.3       11.3           1   \n",
      "2856853      0     4       1       1        14.5       10.4           1   \n",
      "3414306      0     3       0       0        12.0       11.3           1   \n",
      "3345433      0     3       0       0        12.0       11.3           1   \n",
      "...        ...   ...     ...     ...         ...        ...         ...   \n",
      "1379559      0     2       0       0         8.5        7.5           1   \n",
      "2811544      0     2       0       1         8.3        7.5           1   \n",
      "4060571      0     3       0       0        15.3       11.3           1   \n",
      "588179       0     3       0       0        12.1       11.1           1   \n",
      "2005         0     2       0       0         8.5        7.5           1   \n",
      "\n",
      "         outshoulder  upslope  downslope  ...  volume_T  volume    PCU  \\\n",
      "262035             0     0.00        0.0  ...         0      52   52.6   \n",
      "4143296            3     0.00        2.0  ...        20     313  351.6   \n",
      "2856853            1     2.00        0.0  ...         1      68   73.2   \n",
      "3414306            0     0.00        0.0  ...        24     406  448.6   \n",
      "3345433            0     0.00        0.0  ...        13     391  410.0   \n",
      "...              ...      ...        ...  ...       ...     ...    ...   \n",
      "1379559            0     0.00        0.0  ...        14     213  239.0   \n",
      "2811544            0     2.02        0.0  ...        12     251  272.0   \n",
      "4060571            3     0.00        2.0  ...        14     298  327.0   \n",
      "588179             0     2.03        2.0  ...        14     258  296.0   \n",
      "2005               0     0.00        0.0  ...         4      82   89.6   \n",
      "\n",
      "         Speed_volume  Speed_PCU  heavy_rate CrashType DayType  PeakHour Hour  \n",
      "262035              0          0       0.019        \\N       0         0    0  \n",
      "4143296             0          0       0.163        \\N       0         0   13  \n",
      "2856853             0          0       0.118        \\N       1         0    4  \n",
      "3414306             0          0       0.135        \\N       0         0   12  \n",
      "3345433             0          0       0.059        \\N       1         0   13  \n",
      "...               ...        ...         ...       ...     ...       ...  ...  \n",
      "1379559             0          0       0.160        \\N       0         0   19  \n",
      "2811544             0          0       0.108        \\N       0         1    7  \n",
      "4060571             0          0       0.131        \\N       0         1    7  \n",
      "588179              0          0       0.209        \\N       0         0    9  \n",
      "2005                0          0       0.122        \\N       2         0   23  \n",
      "\n",
      "[999086 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "data_sample[\"crash\"] = data_sample[\"crash\"].astype('int32') #temporarily transform crash data into int32 -> for downsampling\n",
    "no_crash = data_sample[data_sample.crash==0]\n",
    "crash = data_sample[data_sample.crash>=1]\n",
    "print(no_crash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample[\"crash\"] = data_sample[\"crash\"].astype(\"category\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample majority\n",
    "no_crash_downsampled = resample(no_crash,\n",
    "                          replace=False, # sample with replacement\n",
    "                          n_samples=len(crash)*1, # match number in majority class\n",
    "                          random_state=27) # reproducible results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([no_crash_downsampled, crash])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_Y = downsampled['crash']\n",
    "down_X = downsampled.drop(['crash'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    914\n",
      "1    904\n",
      "2     10\n",
      "Name: crash, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#確認兩類別數目相同\n",
    "print(downsampled.crash.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lane minlane addlane  totalwidth  lanewidth  inshoulder  outshoulder  \\\n",
      "192840      3       0       0        14.4       10.9           0            0   \n",
      "891911      3       0       0        15.4       11.4           1            3   \n",
      "4994730     3       0       0        13.7       11.0           1            0   \n",
      "2198220     3       0       0        13.7       11.0           1            0   \n",
      "4985643     3       0       0        15.2       11.1           1            3   \n",
      "\n",
      "         upslope  downslope  upslopelength  ...  volume_T  volume    PCU  \\\n",
      "192840       2.0        2.0             11  ...        12     118  139.0   \n",
      "891911       0.0        0.0              0  ...         6     408  427.8   \n",
      "4994730      0.0        0.0              0  ...        20     143  179.8   \n",
      "2198220      0.0        0.0              0  ...        19     508  545.6   \n",
      "4985643      0.0        0.0              0  ...         9     440  462.8   \n",
      "\n",
      "         Speed_volume  Speed_PCU heavy_rate CrashType  DayType PeakHour Hour  \n",
      "192840              0          0      0.229        \\N        0        0   21  \n",
      "891911              0          0      0.071        \\N        0        0   16  \n",
      "4994730             0          0      0.336        \\N        0        0    5  \n",
      "2198220             0          0      0.098        \\N        0        1    7  \n",
      "4985643             0          0      0.073        \\N        1        0   13  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "192840     0\n",
      "891911     0\n",
      "4994730    0\n",
      "2198220    0\n",
      "4985643    0\n",
      "Name: crash, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#確認資料內容\n",
    "print(down_X.head())\n",
    "print(down_Y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate X and Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_Y = data_sample['crash']\n",
    "data_X = data_sample[features] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DO NOT NEED TO MANUALLY CONVERT FEATURES INTO DUMMY VARIABLES\n",
    "* all categorial types will automatically convert to categorial variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-4cc4ec4ae6a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"X = {data_X.columns}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_X' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"X = {data_X.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_X.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WangRabbit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:530: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'A3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-f0045341ee6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdown_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdown_Y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mF1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdown_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdown_Y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"f1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdown_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdown_Y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"precision\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    392\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 232\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    144\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[0;32m    145\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'A3'"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear', C=1)\n",
    "accuracy = cross_val_score(svc,down_X,down_Y,cv=5,scoring=\"accuracy\")\n",
    "F1 = cross_val_score(svc,down_X,down_Y,cv=5,scoring=\"f1\")\n",
    "precision = cross_val_score(svc,down_X,down_Y,cv=5,scoring=\"precision\")\n",
    "recall = cross_val_score(svc,down_X,down_Y,cv=5,scoring=\"recall\")\n",
    "\n",
    "print(\"accuracy = \",accuracy)\n",
    "print(\"accuracy_mean = \",accuracy.mean())\n",
    "print(\"F1 = \",F1)\n",
    "print(\"precision = \",precision)\n",
    "print(\"recall = \",recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert crash values to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace crash values\n",
    "## convert crash values to 1\n",
    "data.loc[data[\"crash\"] >= 1, \"crash\"] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert it to .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=sm.Logit(y_train,X_train,random_state=0)\n",
    "result=model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "#\n",
    "y_pred=logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
